{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DroughtPrediction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mskansara/multivariate_lstm/blob/master/DroughtPrediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DsfHRQX7lBsh",
        "colab_type": "code",
        "outputId": "e480dfb0-2109-444b-db2d-b3e58c944441",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from matplotlib import pyplot\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, RepeatVector, TimeDistributed\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from numpy import array\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint\n",
        "from keras.optimizers import Adam\n",
        "import math\n",
        "\n",
        "NAME='DroughtPrediction'\n",
        "\n",
        "# convert series to supervised learning\n",
        "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
        "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
        "\tdf = pd.DataFrame(data)\n",
        "\tcols, names = list(), list()\n",
        "\t# input sequence (t-n, ... t-1)\n",
        "\tfor i in range(n_in, 0, -1):\n",
        "\t\tcols.append(df.shift(i))\n",
        "\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
        "\t# forecast sequence (t, t+1, ... t+n)\n",
        "\tfor i in range(0, n_out):\n",
        "\t\tcols.append(df.shift(-i))\n",
        "\t\tif i == 0:\n",
        "\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
        "\t\telse:\n",
        "\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
        "\t# put it all together\n",
        "\tagg = pd.concat(cols, axis=1)\n",
        "\tagg.columns = names\n",
        "\t# drop rows with NaN values\n",
        "\tif dropnan:\n",
        "\t\tagg.dropna(inplace=True)\n",
        "\treturn agg\n",
        "\n",
        "#Get dataset\n",
        "# dataset = pd.read_csv('RoughSPI.csv')\n",
        "dataset = read_csv('pollution.csv', header=0, index_col=0)\n",
        "dataset = dataset.drop(['year', 'month', 'day','hour'],axis=1)\n",
        "scaled = dataset.values\n",
        "\n",
        "# dataset = pd.read_csv('pollutioncopy.csv', header=0, index_col=0)\n",
        "# dataset = dataset.drop(['cbwd'], axis=1)\n",
        "\n",
        "# dataset.index = dataset['Time']\n",
        "# dataset.index.name = 'Time'\n",
        "# dataset = dataset.drop(['Time','Location'], axis=1)\n",
        "# print(len(dataset))\n",
        "\n",
        "# print(dataset.head(5))\n",
        "\n",
        "# Standardize the data\n",
        "# dataset_columns = dataset.columns\n",
        "# scaler = preprocessing.StandardScaler()\n",
        "# dataset = scaler.fit_transform(dataset)\n",
        "# dataset = pd.DataFrame(dataset,columns=dataset_columns)\n",
        "# scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "# dataset = scaler.fit_transform(dataset)\n",
        "\n",
        "# print(dataset[0])\n",
        "\n",
        "reframed = series_to_supervised(dataset, 1, 1)\n",
        "# print(reframed)\n",
        "\n",
        "\n",
        "#Splitting features and output\n",
        "# X_train, X_test, Y_train, Y_test = train_test_split(dataset[:,:-1], dataset[:,-1], test_size=0.15)\n",
        "values = reframed.values\n",
        "n_train_hours = 39000\n",
        "\n",
        "train = values[:n_train_hours, :]\n",
        "test = values[n_train_hours:, :]\n",
        "# print(len(train))\n",
        "# print(len(test))\n",
        "\n",
        "# split into input and outputs\n",
        "X_train,Y_train = train[:, :-1], train[:, -1]\n",
        "X_test, Y_test = test[:, :-1], test[:, -1]\n",
        "\n",
        "X_train = np.reshape(X_train, (X_train.shape[0],1,X_train.shape[1]))\n",
        "X_test = np.reshape(X_test, (X_test.shape[0],1,X_test.shape[1]))\n",
        "print(Y_test[0])\n",
        "\n",
        "# print(Y_train)\n",
        "\n",
        "#Create a model\n",
        "model = Sequential()\n",
        "\n",
        "#Stacked LSTM\n",
        "model.add(LSTM(128, input_shape=(X_train.shape[1], X_train.shape[2]),activation='relu', return_sequences=True))\n",
        "model.add(LSTM(64, activation='relu', return_sequences=True))\n",
        "model.add(LSTM(64, activation='relu', return_sequences=True))\n",
        "model.add(LSTM(64, activation='relu', return_sequences=True))\n",
        "model.add(LSTM(64, activation='relu', return_sequences=True))\n",
        "model.add(LSTM(32, activation='relu', return_sequences=False))\n",
        "model.add(Dense(1, activation='relu'))\n",
        "print(model.summary())\n",
        "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(NAME))\n",
        "\n",
        "model.compile(optimizer='Adam', loss='mean_squared_error', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "# fit model\n",
        "history = model.fit(X_train,Y_train,\n",
        "                    epochs=100, \n",
        "                    callbacks=[tensorboard],\n",
        "                    validation_data = (X_test,Y_test)\n",
        "                    )\n",
        "\n",
        "# plot history\n",
        "pyplot.plot(history.history['acc'], label='train')\n",
        "pyplot.plot(history.history['val_acc'], label='test')\n",
        "pyplot.legend()\n",
        "pyplot.show()\n",
        "\n",
        "# plot history\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "pyplot.plot(history.history['val_loss'], label='test')\n",
        "pyplot.legend()\n",
        "pyplot.show()\n",
        "trainPredict = model.predict(X_train)\n",
        "testPredict = model.predict(X_test)\n",
        "\n",
        "# Score model\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(score)\n",
        "\n",
        "#Calculate root mean squared error\n",
        "# trainScore = math.sqrt(mean_squared_error(Y_train[0], trainPredict[:,0]))\n",
        "# print('Train Score: %.2f RMSE' % (trainScore))\n",
        "# testScore = math.sqrt(mean_squared_error(Y_test[0], testPredict[:,0]))\n",
        "# print('Test Score: %.2f RMSE' % (testScore))\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.66\n",
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_73 (LSTM)               (None, 1, 128)            69632     \n",
            "_________________________________________________________________\n",
            "lstm_74 (LSTM)               (None, 1, 64)             49408     \n",
            "_________________________________________________________________\n",
            "lstm_75 (LSTM)               (None, 1, 64)             33024     \n",
            "_________________________________________________________________\n",
            "lstm_76 (LSTM)               (None, 1, 64)             33024     \n",
            "_________________________________________________________________\n",
            "lstm_77 (LSTM)               (None, 1, 64)             33024     \n",
            "_________________________________________________________________\n",
            "lstm_78 (LSTM)               (None, 32)                12416     \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 230,561\n",
            "Trainable params: 230,561\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 39000 samples, validate on 4823 samples\n",
            "Epoch 1/100\n",
            "39000/39000 [==============================] - 48s 1ms/step - loss: 0.1288 - acc: 0.2000 - val_loss: 0.1219 - val_acc: 0.2001\n",
            "Epoch 2/100\n",
            "39000/39000 [==============================] - 28s 719us/step - loss: 0.1222 - acc: 0.2000 - val_loss: 0.1219 - val_acc: 0.2001\n",
            "Epoch 3/100\n",
            "39000/39000 [==============================] - 27s 694us/step - loss: 0.1219 - acc: 0.2000 - val_loss: 0.1219 - val_acc: 0.2001\n",
            "Epoch 4/100\n",
            "39000/39000 [==============================] - 28s 714us/step - loss: 0.1219 - acc: 0.2000 - val_loss: 0.1219 - val_acc: 0.2001\n",
            "Epoch 5/100\n",
            "39000/39000 [==============================] - 28s 710us/step - loss: 0.1220 - acc: 0.2000 - val_loss: 0.1219 - val_acc: 0.2001\n",
            "Epoch 6/100\n",
            "39000/39000 [==============================] - 28s 712us/step - loss: 0.1220 - acc: 0.2000 - val_loss: 0.1219 - val_acc: 0.2001\n",
            "Epoch 7/100\n",
            "39000/39000 [==============================] - 26s 665us/step - loss: 0.1284 - acc: 0.1992 - val_loss: 0.1219 - val_acc: 0.2001\n",
            "Epoch 8/100\n",
            "39000/39000 [==============================] - 28s 710us/step - loss: 0.1220 - acc: 0.2000 - val_loss: 0.1221 - val_acc: 0.2001\n",
            "Epoch 9/100\n",
            "39000/39000 [==============================] - 28s 714us/step - loss: 0.1219 - acc: 0.2000 - val_loss: 0.1219 - val_acc: 0.2001\n",
            "Epoch 10/100\n",
            "39000/39000 [==============================] - 27s 682us/step - loss: 0.1219 - acc: 0.2000 - val_loss: 0.1219 - val_acc: 0.2001\n",
            "Epoch 11/100\n",
            "39000/39000 [==============================] - 28s 721us/step - loss: 0.1220 - acc: 0.2000 - val_loss: 0.1219 - val_acc: 0.2001\n",
            "Epoch 12/100\n",
            "39000/39000 [==============================] - 28s 714us/step - loss: 0.1219 - acc: 0.2000 - val_loss: 0.1219 - val_acc: 0.2001\n",
            "Epoch 13/100\n",
            "39000/39000 [==============================] - 28s 715us/step - loss: 0.1219 - acc: 0.2000 - val_loss: 0.1219 - val_acc: 0.2001\n",
            "Epoch 14/100\n",
            "39000/39000 [==============================] - 27s 690us/step - loss: 0.1425 - acc: 0.2000 - val_loss: 0.2227 - val_acc: 0.2001\n",
            "Epoch 15/100\n",
            "39000/39000 [==============================] - 28s 706us/step - loss: 0.2228 - acc: 0.2000 - val_loss: 0.2227 - val_acc: 0.2001\n",
            "Epoch 16/100\n",
            "39000/39000 [==============================] - 27s 700us/step - loss: 0.2228 - acc: 0.2000 - val_loss: 0.2227 - val_acc: 0.2001\n",
            "Epoch 17/100\n",
            "39000/39000 [==============================] - 27s 694us/step - loss: 0.2228 - acc: 0.2000 - val_loss: 0.2227 - val_acc: 0.2001\n",
            "Epoch 18/100\n",
            "39000/39000 [==============================] - 27s 688us/step - loss: 0.2228 - acc: 0.2000 - val_loss: 0.2227 - val_acc: 0.2001\n",
            "Epoch 19/100\n",
            "39000/39000 [==============================] - 28s 708us/step - loss: 0.2228 - acc: 0.2000 - val_loss: 0.2227 - val_acc: 0.2001\n",
            "Epoch 20/100\n",
            "39000/39000 [==============================] - 28s 708us/step - loss: 0.2007 - acc: 0.2000 - val_loss: 0.1267 - val_acc: 0.2001\n",
            "Epoch 21/100\n",
            "39000/39000 [==============================] - 27s 683us/step - loss: 0.1268 - acc: 0.2000 - val_loss: 0.1267 - val_acc: 0.2001\n",
            "Epoch 22/100\n",
            "39000/39000 [==============================] - 28s 714us/step - loss: 0.1268 - acc: 0.2000 - val_loss: 0.1267 - val_acc: 0.2001\n",
            "Epoch 23/100\n",
            "39000/39000 [==============================] - 28s 725us/step - loss: 0.1268 - acc: 0.2000 - val_loss: 0.1267 - val_acc: 0.2001\n",
            "Epoch 24/100\n",
            "39000/39000 [==============================] - 27s 695us/step - loss: 0.1268 - acc: 0.2000 - val_loss: 0.1267 - val_acc: 0.2001\n",
            "Epoch 25/100\n",
            "39000/39000 [==============================] - 28s 712us/step - loss: 0.1268 - acc: 0.2000 - val_loss: 0.1267 - val_acc: 0.2001\n",
            "Epoch 26/100\n",
            "39000/39000 [==============================] - 27s 704us/step - loss: 0.1268 - acc: 0.2000 - val_loss: 0.1267 - val_acc: 0.2001\n",
            "Epoch 27/100\n",
            "39000/39000 [==============================] - 26s 673us/step - loss: 0.1268 - acc: 0.2000 - val_loss: 0.1267 - val_acc: 0.2001\n",
            "Epoch 28/100\n",
            "39000/39000 [==============================] - 27s 690us/step - loss: 0.1268 - acc: 0.2000 - val_loss: 0.1267 - val_acc: 0.2001\n",
            "Epoch 29/100\n",
            "39000/39000 [==============================] - 27s 700us/step - loss: 0.1268 - acc: 0.2000 - val_loss: 0.1267 - val_acc: 0.2001\n",
            "Epoch 30/100\n",
            "39000/39000 [==============================] - 27s 698us/step - loss: 0.1268 - acc: 0.2000 - val_loss: 0.1267 - val_acc: 0.2001\n",
            "Epoch 31/100\n",
            "39000/39000 [==============================] - 27s 690us/step - loss: 0.1268 - acc: 0.2000 - val_loss: 0.1267 - val_acc: 0.2001\n",
            "Epoch 32/100\n",
            "39000/39000 [==============================] - 28s 714us/step - loss: 0.1268 - acc: 0.2000 - val_loss: 0.1267 - val_acc: 0.2001\n",
            "Epoch 33/100\n",
            "39000/39000 [==============================] - 28s 709us/step - loss: 0.1268 - acc: 0.2000 - val_loss: 0.1267 - val_acc: 0.2001\n",
            "Epoch 34/100\n",
            "39000/39000 [==============================] - 27s 702us/step - loss: 0.1268 - acc: 0.2000 - val_loss: 0.1267 - val_acc: 0.2001\n",
            "Epoch 35/100\n",
            "39000/39000 [==============================] - 27s 699us/step - loss: 0.1268 - acc: 0.2000 - val_loss: 0.1267 - val_acc: 0.2001\n",
            "Epoch 36/100\n",
            "39000/39000 [==============================] - 28s 711us/step - loss: 0.1268 - acc: 0.2000 - val_loss: 0.1267 - val_acc: 0.2001\n",
            "Epoch 37/100\n",
            "39000/39000 [==============================] - 28s 713us/step - loss: 0.1268 - acc: 0.2000 - val_loss: 0.1267 - val_acc: 0.2001\n",
            "Epoch 38/100\n",
            "39000/39000 [==============================] - 26s 676us/step - loss: 0.1268 - acc: 0.2000 - val_loss: 0.1267 - val_acc: 0.2001\n",
            "Epoch 39/100\n",
            "39000/39000 [==============================] - 28s 707us/step - loss: 0.1268 - acc: 0.2000 - val_loss: 0.1267 - val_acc: 0.2001\n",
            "Epoch 40/100\n",
            "39000/39000 [==============================] - 28s 707us/step - loss: 0.1268 - acc: 0.2000 - val_loss: 0.1267 - val_acc: 0.2001\n",
            "Epoch 41/100\n",
            "39000/39000 [==============================] - 26s 678us/step - loss: 0.1268 - acc: 0.2000 - val_loss: 0.1267 - val_acc: 0.2001\n",
            "Epoch 42/100\n",
            "39000/39000 [==============================] - 28s 713us/step - loss: 0.1268 - acc: 0.2000 - val_loss: 0.1267 - val_acc: 0.2001\n",
            "Epoch 43/100\n",
            "39000/39000 [==============================] - 28s 720us/step - loss: 0.1268 - acc: 0.2000 - val_loss: 0.1267 - val_acc: 0.2001\n",
            "Epoch 44/100\n",
            "39000/39000 [==============================] - 26s 678us/step - loss: 0.1268 - acc: 0.2000 - val_loss: 0.1267 - val_acc: 0.2001\n",
            "Epoch 45/100\n",
            "39000/39000 [==============================] - 28s 728us/step - loss: 0.1268 - acc: 0.2000 - val_loss: 0.1267 - val_acc: 0.2001\n",
            "Epoch 46/100\n",
            "39000/39000 [==============================] - 28s 709us/step - loss: 0.1268 - acc: 0.2000 - val_loss: 0.1267 - val_acc: 0.2001\n",
            "Epoch 47/100\n",
            "39000/39000 [==============================] - 27s 699us/step - loss: 0.1268 - acc: 0.2000 - val_loss: 0.1267 - val_acc: 0.2001\n",
            "Epoch 48/100\n",
            "39000/39000 [==============================] - 27s 688us/step - loss: 0.1268 - acc: 0.2000 - val_loss: 0.1267 - val_acc: 0.2001\n",
            "Epoch 49/100\n",
            "39000/39000 [==============================] - 28s 715us/step - loss: 0.1268 - acc: 0.2000 - val_loss: 0.1267 - val_acc: 0.2001\n",
            "Epoch 50/100\n",
            "39000/39000 [==============================] - 28s 720us/step - loss: 0.1268 - acc: 0.2000 - val_loss: 0.1267 - val_acc: 0.2001\n",
            "Epoch 51/100\n",
            "39000/39000 [==============================] - 26s 672us/step - loss: 0.1268 - acc: 0.2000 - val_loss: 0.1267 - val_acc: 0.2001\n",
            "Epoch 52/100\n",
            "39000/39000 [==============================] - 28s 711us/step - loss: 0.1268 - acc: 0.2000 - val_loss: 0.1267 - val_acc: 0.2001\n",
            "Epoch 53/100\n",
            "39000/39000 [==============================] - 28s 717us/step - loss: 0.1268 - acc: 0.2000 - val_loss: 0.1267 - val_acc: 0.2001\n",
            "Epoch 54/100\n",
            "39000/39000 [==============================] - 27s 704us/step - loss: 0.1268 - acc: 0.2000 - val_loss: 0.1267 - val_acc: 0.2001\n",
            "Epoch 55/100\n",
            "39000/39000 [==============================] - 27s 699us/step - loss: 0.1268 - acc: 0.2000 - val_loss: 0.1267 - val_acc: 0.2001\n",
            "Epoch 56/100\n",
            "39000/39000 [==============================] - 28s 721us/step - loss: 0.1268 - acc: 0.2000 - val_loss: 0.1267 - val_acc: 0.2001\n",
            "Epoch 57/100\n",
            "39000/39000 [==============================] - 28s 725us/step - loss: 0.1268 - acc: 0.2000 - val_loss: 0.1267 - val_acc: 0.2001\n",
            "Epoch 58/100\n",
            "39000/39000 [==============================] - 26s 677us/step - loss: 0.1268 - acc: 0.2000 - val_loss: 0.1267 - val_acc: 0.2001\n",
            "Epoch 59/100\n",
            "39000/39000 [==============================] - 28s 719us/step - loss: 0.1268 - acc: 0.2000 - val_loss: 0.1267 - val_acc: 0.2001\n",
            "Epoch 60/100\n",
            "39000/39000 [==============================] - 28s 717us/step - loss: 0.1268 - acc: 0.2000 - val_loss: 0.1267 - val_acc: 0.2001\n",
            "Epoch 61/100\n",
            "39000/39000 [==============================] - 26s 677us/step - loss: 0.1268 - acc: 0.2000 - val_loss: 0.1267 - val_acc: 0.2001\n",
            "Epoch 62/100\n",
            "39000/39000 [==============================] - 28s 721us/step - loss: 0.1268 - acc: 0.2000 - val_loss: 0.1267 - val_acc: 0.2001\n",
            "Epoch 63/100\n",
            "39000/39000 [==============================] - 28s 708us/step - loss: 0.1268 - acc: 0.2000 - val_loss: 0.1267 - val_acc: 0.2001\n",
            "Epoch 64/100\n",
            "39000/39000 [==============================] - 27s 683us/step - loss: 0.1268 - acc: 0.2000 - val_loss: 0.1267 - val_acc: 0.2001\n",
            "Epoch 65/100\n",
            "39000/39000 [==============================] - 28s 713us/step - loss: 0.1268 - acc: 0.2000 - val_loss: 0.1267 - val_acc: 0.2001\n",
            "Epoch 66/100\n",
            "39000/39000 [==============================] - 28s 712us/step - loss: 0.1268 - acc: 0.2000 - val_loss: 0.1267 - val_acc: 0.2001\n",
            "Epoch 67/100\n",
            "39000/39000 [==============================] - 28s 727us/step - loss: 0.1268 - acc: 0.2000 - val_loss: 0.1267 - val_acc: 0.2001\n",
            "Epoch 68/100\n",
            "39000/39000 [==============================] - 27s 696us/step - loss: 0.1268 - acc: 0.2000 - val_loss: 0.1267 - val_acc: 0.2001\n",
            "Epoch 69/100\n",
            "39000/39000 [==============================] - 28s 712us/step - loss: 0.1268 - acc: 0.2000 - val_loss: 0.1267 - val_acc: 0.2001\n",
            "Epoch 70/100\n",
            "39000/39000 [==============================] - 28s 725us/step - loss: 0.1268 - acc: 0.2000 - val_loss: 0.1267 - val_acc: 0.2001\n",
            "Epoch 71/100\n",
            "39000/39000 [==============================] - 26s 670us/step - loss: 0.1268 - acc: 0.2000 - val_loss: 0.1267 - val_acc: 0.2001\n",
            "Epoch 72/100\n",
            "39000/39000 [==============================] - 28s 717us/step - loss: 0.1268 - acc: 0.2000 - val_loss: 0.1267 - val_acc: 0.2001\n",
            "Epoch 73/100\n",
            "39000/39000 [==============================] - 28s 706us/step - loss: 0.1268 - acc: 0.2000 - val_loss: 0.1267 - val_acc: 0.2001\n",
            "Epoch 74/100\n",
            "39000/39000 [==============================] - 27s 705us/step - loss: 0.1268 - acc: 0.2000 - val_loss: 0.1267 - val_acc: 0.2001\n",
            "Epoch 75/100\n",
            "39000/39000 [==============================] - 27s 703us/step - loss: 0.1268 - acc: 0.2000 - val_loss: 0.1267 - val_acc: 0.2001\n",
            "Epoch 76/100\n",
            "39000/39000 [==============================] - 28s 715us/step - loss: 0.1268 - acc: 0.2000 - val_loss: 0.1267 - val_acc: 0.2001\n",
            "Epoch 77/100\n",
            "39000/39000 [==============================] - 28s 706us/step - loss: 0.1268 - acc: 0.2000 - val_loss: 0.1267 - val_acc: 0.2001\n",
            "Epoch 78/100\n",
            "39000/39000 [==============================] - 27s 684us/step - loss: 0.1268 - acc: 0.2000 - val_loss: 0.1267 - val_acc: 0.2001\n",
            "Epoch 79/100\n",
            "39000/39000 [==============================] - 29s 743us/step - loss: 0.1268 - acc: 0.2000 - val_loss: 0.1267 - val_acc: 0.2001\n",
            "Epoch 80/100\n",
            "39000/39000 [==============================] - 28s 716us/step - loss: 0.1268 - acc: 0.2000 - val_loss: 0.1267 - val_acc: 0.2001\n",
            "Epoch 81/100\n",
            "39000/39000 [==============================] - 27s 692us/step - loss: 0.1268 - acc: 0.2000 - val_loss: 0.1267 - val_acc: 0.2001\n",
            "Epoch 82/100\n",
            "39000/39000 [==============================] - 28s 715us/step - loss: 0.1268 - acc: 0.2000 - val_loss: 0.1267 - val_acc: 0.2001\n",
            "Epoch 83/100\n",
            "39000/39000 [==============================] - 28s 714us/step - loss: 0.1268 - acc: 0.2000 - val_loss: 0.1267 - val_acc: 0.2001\n",
            "Epoch 84/100\n",
            "39000/39000 [==============================] - 27s 687us/step - loss: 0.1268 - acc: 0.2000 - val_loss: 0.1267 - val_acc: 0.2001\n",
            "Epoch 85/100\n",
            "39000/39000 [==============================] - 28s 721us/step - loss: 0.1268 - acc: 0.2000 - val_loss: 0.1267 - val_acc: 0.2001\n",
            "Epoch 86/100\n",
            "39000/39000 [==============================] - 28s 712us/step - loss: 0.1268 - acc: 0.2000 - val_loss: 0.1267 - val_acc: 0.2001\n",
            "Epoch 87/100\n",
            "39000/39000 [==============================] - 28s 714us/step - loss: 0.1268 - acc: 0.2000 - val_loss: 0.1267 - val_acc: 0.2001\n",
            "Epoch 88/100\n",
            "39000/39000 [==============================] - 26s 676us/step - loss: 0.1268 - acc: 0.2000 - val_loss: 0.1267 - val_acc: 0.2001\n",
            "Epoch 89/100\n",
            "39000/39000 [==============================] - 28s 706us/step - loss: 0.1268 - acc: 0.2000 - val_loss: 0.1267 - val_acc: 0.2001\n",
            "Epoch 90/100\n",
            "39000/39000 [==============================] - 28s 725us/step - loss: 0.1268 - acc: 0.2000 - val_loss: 0.1267 - val_acc: 0.2001\n",
            "Epoch 91/100\n",
            "39000/39000 [==============================] - 27s 680us/step - loss: 0.1268 - acc: 0.2000 - val_loss: 0.1267 - val_acc: 0.2001\n",
            "Epoch 92/100\n",
            "39000/39000 [==============================] - 28s 705us/step - loss: 0.1268 - acc: 0.2000 - val_loss: 0.1267 - val_acc: 0.2001\n",
            "Epoch 93/100\n",
            "39000/39000 [==============================] - 28s 705us/step - loss: 0.1268 - acc: 0.2000 - val_loss: 0.1267 - val_acc: 0.2001\n",
            "Epoch 94/100\n",
            "39000/39000 [==============================] - 27s 702us/step - loss: 0.1268 - acc: 0.2000 - val_loss: 0.1267 - val_acc: 0.2001\n",
            "Epoch 95/100\n",
            "39000/39000 [==============================] - 28s 722us/step - loss: 0.1268 - acc: 0.2000 - val_loss: 0.1267 - val_acc: 0.2001\n",
            "Epoch 96/100\n",
            "39000/39000 [==============================] - 28s 710us/step - loss: 0.1268 - acc: 0.2000 - val_loss: 0.1267 - val_acc: 0.2001\n",
            "Epoch 97/100\n",
            "39000/39000 [==============================] - 27s 698us/step - loss: 0.1268 - acc: 0.2000 - val_loss: 0.1267 - val_acc: 0.2001\n",
            "Epoch 98/100\n",
            "39000/39000 [==============================] - 26s 677us/step - loss: 0.1268 - acc: 0.2000 - val_loss: 0.1267 - val_acc: 0.2001\n",
            "Epoch 99/100\n",
            "39000/39000 [==============================] - 28s 709us/step - loss: 0.1268 - acc: 0.2000 - val_loss: 0.1267 - val_acc: 0.2001\n",
            "Epoch 100/100\n",
            "39000/39000 [==============================] - 27s 700us/step - loss: 0.1268 - acc: 0.2000 - val_loss: 0.1267 - val_acc: 0.2001\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAD8CAYAAABpcuN4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzFpyUJiZWUv/Hw9rZK+n+xrQAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nC64Ums+KG2gAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[0.12670115110675453, 0.20008293589800688]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocvFaapm8_h8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}